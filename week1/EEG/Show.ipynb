{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab\n",
    "%matplotlib inline \n",
    "import os\n",
    "import sys; sys.path.append(\"..\")\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Prameters\n",
    "method='csp'\n",
    "data_name='aa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "filename = 'data_set_IVa_{}'.format(data_name)\n",
    "data_dir = os.path.join(\"./Datasets/\", filename)\n",
    "data_path = os.path.join(data_dir, filename + '_' + method + '.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "result = utils.test_model(df)\n",
    "\n",
    "res_df = pd.DataFrame(result)\n",
    "res_df.columns = ['method', 'score']\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show different model\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.vlines(x=res_df['method'], ymin=0, ymax=res_df['score'], color='firebrick', alpha=0.7, linewidth=2)\n",
    "plt.scatter(res_df['method'], res_df['score'], s=275, color='firebrick', alpha=0.5)\n",
    "\n",
    "for k in res_df.values:\n",
    "    plt.text(k[0], k[1]*1.1, round(k[1], 4), horizontalalignment= 'center', verticalalignment='bottom', fontsize=14)\n",
    "\n",
    "plt.ylim([0, max(res_df['score'])*1.2])\n",
    "plt.xticks(fontsize=20, rotation=45);\n",
    "plt.yticks(fontsize=20);\n",
    "plt.ylabel('Score', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(res_df, save_path=None):\n",
    "    plt.figure(figsize=(24, 12))\n",
    "    plt.vlines(x=res_df['method'], ymin=0, ymax=res_df['score'], color='firebrick', alpha=0.7, linewidth=2)\n",
    "    plt.scatter(res_df['method'], res_df['score'], s=275, color='firebrick', alpha=0.5)\n",
    "\n",
    "    for k in res_df.values:\n",
    "        plt.text(k[0], k[1]*1.1, round(k[1], 4), horizontalalignment= 'center', verticalalignment='bottom', fontsize=22)\n",
    "\n",
    "    plt.ylim([0, max(res_df['score'])*1.2])\n",
    "    plt.xticks(fontsize=20, rotation=45);\n",
    "    plt.yticks(fontsize=20);\n",
    "    plt.ylabel('Score', fontsize=20);\n",
    "    if save_path != None:\n",
    "        plt.savefig(save_path, bbox_inches = 'tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Prameters\n",
    "data_name='aa' # 'aa', 'al', 'av', 'aw', 'ay'\n",
    "method='csp'  # 'csp', 'bandpowers', 'dct', 'wavelet'\n",
    "\n",
    "\n",
    "filename='data_set_IVa_{}'.format(data_name)\n",
    "data_path = os.path.join('./result', filename, filename + '_{}'.format(method)+'_result.csv')\n",
    "res_df = pd.read_csv(data_path)\n",
    "show(res_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_name='aa' # \n",
    "method='csp'  # 'csp', 'bandpowers', 'dct', 'wavelet'\n",
    "for data_name in ['aa', 'al', 'av', 'aw', 'ay']:\n",
    "    for method in ['csp', 'bandpowers', 'dct', 'wavelet']:\n",
    "        filename='data_set_IVa_{}'.format(data_name)\n",
    "        data_path = os.path.join('./result', filename, filename + '_{}'.format(method)+'_result.csv')\n",
    "        res_df = pd.read_csv(data_path)\n",
    "        \n",
    "        save_dir = os.path.join('./result', 'pic')\n",
    "        save_path = os.path.join(save_dir, filename + '_{}'.format(method)+'_result.png')\n",
    "        show(res_df, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 拼接所有的数据\n",
    "for method in ['csp', 'bandpowers', 'dct', 'wavelet', 'all']:\n",
    "    filename='data_set_IVa_{}'.format(data_name)\n",
    "    data_path = os.path.join('./result/data_all', 'data_all_{}'.format(method)+'_result.csv')\n",
    "    res_df = pd.read_csv(data_path)\n",
    "\n",
    "    save_dir = os.path.join('./result', 'pic')\n",
    "    save_path = os.path.join(save_dir, 'data_all_{}'.format(method)+'_result.png')\n",
    "    show(res_df, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the best model\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import *\n",
    "\n",
    "def Evaluate(model, X, y, index=0):\n",
    "    AS, MIS, MAS, RS, F1S, KS = [], [], [], [], [], []\n",
    "    for i in range(5):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        if index == 0:\n",
    "            model.fit(X_train)\n",
    "            \n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        AS.append(accuracy_score(y_test, y_pred)) # 准确率\n",
    "        MIS.append(precision_score(y_test, y_pred, average='micro'))\n",
    "        MAS.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        RS.append(recall_score(y_test, y_pred, average='micro'))\n",
    "        F1S.append(f1_score(y_test, y_pred,  average='weighted'))\n",
    "        KS.append(cohen_kappa_score(y_test, y_pred))\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'index':['Accuracy', 'Micro Average', 'Macro Average', 'Recall Score', 'F1 Score', 'Kappa Score'],\n",
    "        'score':[min(round(i, 4), 1.0000) for i in [mean(AS), mean(MIS), mean(MAS), mean(RS), mean(F1S), mean(KS)]]\n",
    "    })\n",
    "\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "clf = QuadraticDiscriminantAnalysis(priors=None, \n",
    "                                        reg_param=0.0, \n",
    "                                        store_covariance=False, \n",
    "                                        tol=1e-4)\n",
    "# clf.fit(X, y) \n",
    "\n",
    "res_df = Evaluate(clf, X, y, index=1)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.vlines(x=res_df['index'], ymin=0, ymax=res_df['score'], color='firebrick', alpha=0.7, linewidth=2)\n",
    "plt.scatter(res_df['index'], res_df['score'], s=275, color='firebrick', alpha=0.5)\n",
    "\n",
    "for k in res_df.values:\n",
    "    plt.text(k[0], k[1]+0.1, k[1], horizontalalignment= 'center', verticalalignment='bottom', fontsize=14)\n",
    "\n",
    "plt.ylim([0, max( res_df['score'])*1.5])\n",
    "plt.xticks(fontsize=20, rotation=45);\n",
    "plt.yticks(fontsize=20);\n",
    "plt.ylabel('Score', fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('torch': conda)",
   "language": "python",
   "name": "python37964bittorchcondafedecf766d274506ac4f438154f4c34c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}